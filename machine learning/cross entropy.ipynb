{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a294ca8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.2329,  0.0874],\n",
      "         [ 0.1125,  0.2165],\n",
      "         [-0.8925, -0.9911],\n",
      "         [ 1.4547, -0.3800]],\n",
      "\n",
      "        [[ 2.0217, -1.6869],\n",
      "         [-0.1707,  1.0131],\n",
      "         [-0.6896, -0.5333],\n",
      "         [-1.4634, -0.6466]]], requires_grad=True)\n",
      "after flatten tensor([[-1.2329,  0.0874],\n",
      "        [ 0.1125,  0.2165],\n",
      "        [-0.8925, -0.9911],\n",
      "        [ 1.4547, -0.3800],\n",
      "        [ 2.0217, -1.6869],\n",
      "        [-0.1707,  1.0131],\n",
      "        [-0.6896, -0.5333],\n",
      "        [-1.4634, -0.6466]], grad_fn=<ViewBackward0>)\n",
      "tensor([[1, 0, 0, 1],\n",
      "        [0, 0, 0, 0]])\n",
      "after flatten tensor([1, 0, 0, 1, 0, 0, 0, 0])\n",
      "tensor(0.8804, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "vocab_size=2\n",
    "batch_size=2\n",
    "seq_len=4\n",
    "\n",
    "\n",
    "input = torch.randn(batch_size, seq_len, vocab_size, requires_grad=True) \n",
    "print(input) # (batch_size, seq_len, vocab_size)\n",
    "print('after flatten', input.view(-1, vocab_size))\n",
    "\n",
    "target = torch.randint(vocab_size, (batch_size,seq_len,), dtype=torch.int64)\n",
    "print(target) # (batch_size, seq_len)\n",
    "print('after flatten', target.view(-1))\n",
    "\n",
    "# use index\n",
    "loss = F.cross_entropy(input.view(-1,vocab_size), target.view(-1))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9965fa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "perfect_input = torch.FloatTensor([[[-math.inf, 1.5294],\n",
    "                            [-math.inf, 1.0159],\n",
    "                            [-math.inf, 1.2443],\n",
    "                            [-math.inf, 1.0776]],\n",
    "                           [[1.5253,  -math.inf],\n",
    "                            [-math.inf, 1.9067],\n",
    "                            [-math.inf, 0.5606],\n",
    "                            [ 1.1483,  -math.inf]]])\n",
    "truth = torch.LongTensor(\n",
    "    [[1, 1, 1, 1],\n",
    "    [0, 1, 1, 0]]\n",
    ")\n",
    "\n",
    "zero_loss = F.cross_entropy(perfect_input.view(-1, vocab_size), truth.view(-1))\n",
    "print(zero_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d119384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
