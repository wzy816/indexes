# LLMs Get Lost In Multi-Turn Conversation

## 我们要讨论的论文链接是 <https://arxiv.org/pdf/2505.06120> 请分别回答一下以下问题 1. 这篇论文试图解决什么问题？2. 有哪些相关研究？3. 论文如何解决这个问题？4. 论文做了哪些实验？5. 有什么可以进一步探索的点？6. 总结一下论文的主要内容。并以此为基础，继续回答我后面的其它问题

1. **这篇论文试图解决什么问题？**
     * 这篇论文试图解决大型语言模型（LLMs）在多轮对话中性能显著下降的问题。尽管 LLMs 在单轮、完全指定指令的场景下表现出色，但在实际的多轮对话中，用户指令通常不完整（underspecified），而 LLMs 在这种多轮、不完整指令的对话场景下的表现较差，平均性能下降了 39%。论文通过大规模模拟实验来比较 LLMs 在单轮和多轮设置下的表现，探索 LLMs 在多轮对话中性能下降的原因。

2. **有哪些相关研究？**
     * 评估 LLMs 多轮对话能力的相关研究包括 MT - bench 等，这些研究最初利用众包注释来评估 LLM 作为评估者的能力，后续工作在 MT - bench 的基础上进行了扩展，包括增加对话长度、提高评估粒度等。但大多数先前工作将对话视为情节性的（episodic），即对话回合之间虽然有关系，但可以将对话分解为可独立评估的子任务。与之不同的是，这篇论文强调不完整指令在多轮对话中的普遍性，并创建了一个模拟环境来专门评估 LLMs 在多轮不完整指令对话中的表现。

3. **论文如何解决这个问题？**
     * 论文创建了一个名为“分片模拟（sharded simulation）”的模拟环境，将现有的单轮指令转换为分片指令，通过模拟多轮对话来评估 LLMs 的性能。分片模拟确保每轮对话最多只揭示一个指令分片，从而逐渐揭示完整指令。论文通过这种模拟方式对六个生成任务进行实验，比较了 LLMs 在单轮和多轮对话中的表现，并分析了性能下降的原因，将其分解为能力下降和可靠性降低两个部分。此外，论文还探讨了一些可能的解决方案，如通过代理式的总结（RECAP）和滚雪球（SNOWBALL）模拟类型来改善 LLMs 在多轮对话中的表现。

4. **论文做了哪些实验？**
     * 论文进行了大规模的模拟实验，涉及六个生成任务，包括代码编写、数据库查询、API 调用、数学问题解决、数据转文本和摘要生成等。实验涵盖了从较小的开放权重模型（如 LLama3.1 - 8B - Instruct）到最先进的模型（如 Gemini 2.5 Pro）的 15 个 LLMs。对于每个任务，论文都从高质量的单轮、完全指定基准测试中选取指令，并进行分片处理。实验模拟了三种对话类型：FULL（单轮、完全指定）、CONCAT（单轮、基于分片指令）和 SHARDED（多轮、不完整指令）。通过这些实验，论文评估了 LLMs 的平均性能、能力（aptitude）和可靠性（reliability），并发现 LLMs 在多轮对话中的可靠性显著降低，且所有测试的 LLMs 都表现出较高的不可靠性，而能力下降相对较小。

5. **有什么可以进一步探索的点？**
     * 论文提到的进一步探索点包括：
     * **对更广泛任务的评估** ：论文主要关注分析性任务，未来可以扩展到更具创造性的任务，以确定 LLMs 在这些任务中是否也会出现类似的性能下降。
     * **对不同语言和多模态任务的评估** ：目前的研究主要集中在英语文本任务上，未来可以探索 LLMs 在其他语言以及涉及多模态（如图像、语音等）的多轮对话中的表现。
     * **改进模拟环境的现实性** ：尽管论文的模拟环境提供了一个可扩展的实验平台，但它可能无法完全捕捉人类与 AI 对话中的所有复杂动态。未来可以通过引入更多人类参与的对话数据来提高模拟环境的现实性。
     * **探索降低温度对不同类型任务的影响** ：论文发现降低 LLMs 的生成温度在多轮对话中对提高可靠性效果有限，未来可以进一步研究在不同任务类型和对话场景下，如何更好地调整温度等参数以优化 LLMs 的多轮对话性能。

6. **总结一下论文的主要内容。**
     * 这篇论文研究了大型语言模型（LLMs）在多轮对话中的性能问题。通过创建分片模拟环境，论文发现 LLMs 在多轮、不完整指令的对话场景下性能显著下降，平均下降 39%，并且主要表现为可靠性大幅降低。论文分析了 LLMs 在多轮对话中出现性能下降的原因，包括过早提出假设、过度依赖之前的错误回答尝试、对用户指令的不完整信息做出错误假设以及生成过于冗长的回答等。实验结果表明，即使是最先进的 LLMs 也无法有效处理多轮对话中的不完整指令，且降低生成温度等常见方法在多轮对话中效果不佳。论文呼吁 LLMs 的开发者在未来模型迭代中同时优化模型的能力和可靠性，并为系统构建者、NLP 实践者和用户提供了相应的建议。
